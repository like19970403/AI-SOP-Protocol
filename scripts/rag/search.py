#!/usr/bin/env python3
"""
RAG Search
æŸ¥è©¢æœ¬åœ°å‘é‡çŸ¥è­˜åº«ï¼Œå¬å›ç›¸é—œæ–‡ä»¶ç‰‡æ®µ
"""
import argparse
import sys

def search(query: str, top_k: int = 3, index_path: str = ".rag/index"):
    try:
        import chromadb
        from sentence_transformers import SentenceTransformer
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾è³´ï¼Œè«‹åŸ·è¡Œï¼špip install chromadb sentence-transformers")
        sys.exit(1)

    try:
        client = chromadb.PersistentClient(path=index_path)
        collection = client.get_collection("asp_knowledge")
    except Exception:
        print("âš ï¸  RAG ç´¢å¼•ä¸å­˜åœ¨ï¼Œè«‹å…ˆåŸ·è¡Œï¼šmake rag-index")
        sys.exit(1)

    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    query_embedding = embedder.encode([query]).tolist()

    results = collection.query(
        query_embeddings=query_embedding,
        n_results=top_k,
        include=["documents", "metadatas", "distances"],
    )

    print(f"\nğŸ” æŸ¥è©¢ï¼š{query}")
    print(f"ğŸ“š å¬å› {len(results['documents'][0])} å€‹ç›¸é—œç‰‡æ®µ\n")

    for i, (doc, meta, dist) in enumerate(zip(
        results["documents"][0],
        results["metadatas"][0],
        results["distances"][0],
    )):
        similarity = round(1 - dist, 3)
        print(f"{'â”€'*60}")
        print(f"[{i+1}] ä¾†æºï¼š{meta['source']}ï¼ˆç›¸ä¼¼åº¦ {similarity}ï¼‰")
        print(f"{doc[:400]}{'...' if len(doc) > 400 else ''}")
        print()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--query", required=True)
    parser.add_argument("--top-k", type=int, default=3)
    parser.add_argument("--index", default=".rag/index")
    args = parser.parse_args()
    search(args.query, args.top_k, args.index)
